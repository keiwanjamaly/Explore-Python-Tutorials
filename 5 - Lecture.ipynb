{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Authors:**\n",
    "* Yilber Fabian Bautista \n",
    "* \n",
    "\n",
    "**Last date of modification:**\n",
    " December 23th 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hello there,\n",
    "\n",
    "welcome to Lecture 5 of this mini-lecture series on programing with Python. In this series, you will learn basic and intermediate python tools that will be of great use in your scientific carer.\n",
    "\n",
    "By the end of this lecture you will be able to:\n",
    "* Use **dictionaries** in python\n",
    "* Use **pandas** library to  create, modify, save and read **csv** data files\n",
    "* Plot using **pandas** library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dictionaries\n",
    "\n",
    "In **Lecture 2** we learned how to use **lists** and **arrays** as data structures. In this lecture we introduce **dictionaries**.\n",
    "\n",
    "**What are Dictionaries?**\n",
    "\n",
    "A dictionary consists of keys and values assigned to those keys, often referred to as key-value pairs. Since dictionaries have similar characteristics to lists, it is helpful to compare these two\n",
    "\n",
    "<img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-PY0101EN-SkillsNetwork/labs/Module%202/images/DictsList.png\" width=\"650\" /> \n",
    "\n",
    "Figure taken from [IBM courses](https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-PY0101EN-SkillsNetwork/labs/Module%202/images/DictsList.png)\n",
    "\n",
    "Instead of the numerical indices, dictionaries are indexed by *keys*. Keys are typically *strings*, but any non-mutable objects like *tuples* can also serve as a key.\n",
    "Keys play the role of indices used to access values within a dictionary.\n",
    "\n",
    "Similar to lists, dictionaries are mutable objects, which means we can modify them, change values for a given key, add new key-value pairs, etc. \n",
    "\n",
    "The python syntax to create a dictionary is as follows. Here is a simple dictionary with one key-value pair.\n",
    "```py\n",
    "my_dictionary = {'key':value}\n",
    "```\n",
    "Larger dictionaries are created by separating each key-value pair with a comma, e.g.,\n",
    "```py\n",
    "my_dictionary = {'key1':value1, 'key2':value2}\n",
    "```\n",
    "The `type` of a dictionary is `dict`. \n",
    "\n",
    "Let's create our first dictionary in python below. Note we illustrate:\n",
    "- Keys need not all be the same type. Usually *all* keys will be strings, but other types can be keys too.\n",
    "- Values also need not be the same type, similar to lists and tuples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Create the dictionary\n",
    "\n",
    "my_dictionary = {\"key1\": 1, \"key2\": \"2\", \"key3\": np.array([3, 3, 8]),\n",
    "                 \"key4\": (4, 4, '4'), ('key5'): 5, (0, 1): 6}\n",
    "\n",
    "type(my_dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing the keys of a dictionary:\n",
    "\n",
    "Every dictionary has a built-in method `keys()` to obtain a list of the keys of the dictionary (if you do not know them ahead of time). \n",
    "```py\n",
    "my_dictionary.keys()\n",
    "```\n",
    "\n",
    "### Accessing the value by the key:\n",
    "\n",
    "To access the value for given key, we have two options: \n",
    "- Using *square brackets* similar to accessing elements of a list: \n",
    "```py\n",
    "my_dictionary['key1']\n",
    "```\n",
    "- Using the built-in method `get()`:\n",
    "```py\n",
    "my_dictionary.get('key1')\n",
    "```\n",
    "\n",
    "Both options will return the output `1`. However, they behave differently if a key is *not* in the dictionary. For example,\n",
    "`my_dictionary['key7']` will produce an error message, while `my_dictionary.get('key7')` will yield `None` (with no error message). You can use a syntax like\n",
    "```py\n",
    "if my_dictionary.get('key'):\n",
    "    <Do something>\n",
    "```\n",
    "to perform an action only if `'key'` is found in the dictionary.\n",
    "\n",
    "\n",
    "### Adding new key-value pairs to the dictionary\n",
    "\n",
    "For **lists** and **arrays** we would had use the `list.append(value)` and `np.append(array,value)` methods respectively. For **dictionaries** instead, we will use the following syntax:\n",
    "\n",
    "```py\n",
    "my_dictionary['key7'] = 'new_value'\n",
    "```\n",
    "\n",
    "### Remove a key-value pair from a dictionary\n",
    "\n",
    "To remove a key-value pair, we use the `pop()` method. For instance, \n",
    "```py\n",
    "value = my_dictionary.pop('key7')\n",
    "```\n",
    "will set `value` equal to `'new_value'` *and* it will delete this key-value pair from our dictionary. Now if we ask for the keys of our dictionary \n",
    "```\n",
    "my_dictionary.keys()\n",
    "```\n",
    "we will get as output `dict_keys(['key1', 'key2', 'key3', 'key4', 'key5', (0, 1)])`. If we wanted to delete this key-value pair *without* retaining the value, we can simply do\n",
    "```py\n",
    "my_dictionary.pop('key7')\n",
    "```\n",
    "without assigning it to a variable. \n",
    "\n",
    "See [this link](https://www.w3schools.com/python/python_ref_dictionary.asp) for additional methods applied to dictionaries\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "1. Type out all the commands yourself for the previous lines of code.\n",
    "2. Given the following dictionaries, write short line codes to answer the following questions (See [this page](https://holypython.com/beginner-python-exercises/exercise-8-python-dictionaries/) for more exercises with dictionaries): \n",
    "\n",
    "```py\n",
    "dictionary_1 ={\"name\": \"Plato\", \"country\": \"Ancient Greece\", \"born\": -427, \"teacher\": \"Socrates\", \"student\": \"Aristotle\"}\n",
    "dictionary_2 = {\"son's name\": \"Lucas\", \"son's eyes\": \"green\", \"son's height\": 32, \"son's weight\": 25}\n",
    "```\n",
    "* When was Plato born?\n",
    "* Change Plato's birth year from B.C. 427 to B.C. 428.\n",
    "* Add the key \"work\" to `dictionary_1`, with the values \"Apology\", \"Phaedo\", \"Republic\", \"Symposium\" in a list.\n",
    "* Add 2 inches to the son's height in `dictionary_2`.\n",
    "* Using the `.get()` method, print the value of `\"son's eyes\"`.\n",
    "* Merge `dictionary_1` and `dictionary_2` into the dictionary `dictionary_merge`, using the syntax:\n",
    "```py\n",
    "dictionary_merge = merge(**dictionary_1,**dictionary_2)\n",
    "```\n",
    "and print the list of keys in `dictionary_merge`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The pandas library\n",
    "\n",
    "The **pandas** library is used to efficiently manipulate tabular data such as data stored in spreadsheets or databases, and to do statistics analysis of such data. Pandas supports the integration of several file formats and data sources. Here we focus on `csv` files, but many others are supported as well (e.g., `excel`, `sql`, `json`).\n",
    "\n",
    "You import it as follows:\n",
    "```py\n",
    "import pandas as pd\n",
    "```\n",
    "\n",
    "For a detail view of **pandas** library, see [here](https://pandas.pydata.org/pandas-docs/stable/getting_started/index.html#getting-started), and for Library Highlights see [here](https://pandas.pydata.org/about/index.html).\n",
    "\n",
    "In **pandas**, `DataFrame` objects are the key data structures that are used to store your data. You can think of a `DataFrame` as a spreadsheet. \n",
    "\n",
    "Let us start our pandas journey by creating simple `DataFrame`s from the data structure we learned above, namely, **dictionaries**. We create a `DataFrame` from a dictionary of lists. Then, the dictionary keys will be used as column headers and the values in each list will be the columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a dictionary\n",
    "\n",
    "dictionary =  {\n",
    "        \"Name\": [\n",
    "            \"Braund, Mr. Owen Harris\",\n",
    "            \"Allen, Mr. William Henry\",\n",
    "            \"Bonnell, Ms. Elizabeth\",\n",
    "        ],\n",
    "        \"Age\": [22, 35, 25],\n",
    "        \"Course\": [\"Data Structures\", \"Machine Learning\", \"OOPS with java\"],\n",
    "    }\n",
    "\n",
    "# Now create a DataFrame from a dictionary\n",
    "\n",
    "df = pd.DataFrame(dictionary)\n",
    "\n",
    "# Print out the DataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "\n",
    "Get some experience with `DataFrame`s by creating your own `DataFrame`, similar to the one defined above. (Avoid coping and pasting the code from the text.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with DataFrames\n",
    "\n",
    "DataFrames have many built-in methods and attributes that make them easy to work with. Here we go through the basics.\n",
    "\n",
    "### **The head/tail attributes**\n",
    "\n",
    "The built-in methods `head(i)` and `tail(i)` access the first or last `i` elements of your `DataFrame`, e.g., `df.head(2)` will access the first two elements. This is useful when dealing with large datasets.\n",
    "\n",
    "### **Slicing a DataFrame**\n",
    "\n",
    "To access a desired slice of a `DataFrame`, we use a similar syntax that for `lists`. For example\n",
    "```py\n",
    "sub_df = df[1:3]\n",
    "```\n",
    "takes the slice containing the second and third elements of `df` and saves them in the new `DataFrame` named `sub_df`, with the same attributes as the original DataFrame `df`.\n",
    "\n",
    "\n",
    "### **Keys in a DataFrame**\n",
    "\n",
    "As for dictionaries, we can ask for the `keys` of a  `DataFrame` using the `keys()` method.  In our `df` example \n",
    "```py\n",
    "df.keys()\n",
    "```\n",
    "we get as output `Index(['Name', 'Age', 'Course'], dtype='object')`.\n",
    "\n",
    "One can also access the keys using the attribute `columns`. \n",
    "```py\n",
    "df.columns\n",
    "\n",
    "```\n",
    "\n",
    "### **Accessing a column in a DataFrame**\n",
    "\n",
    "Columns in the `DataFrame` are labeled by keys, using the same syntax as for dictionaries. For instance, to access the column containing all of the names in our `df` defined above we use:\n",
    "\n",
    "```py\n",
    "df['Name']\n",
    "\n",
    "```\n",
    "Note that this produces as an output a list-like `pandas.Series` object with all elements of the `'Name'` column. You can convert this to a true list using\n",
    "```py\n",
    "list(df['Name'])\n",
    "\n",
    "```\n",
    "\n",
    "### **Accessing a row in a DataFrame**\n",
    "\n",
    "To access row `j` in our `DataFrame`, we use the attribute `iloc[j]`. For example\n",
    "```py\n",
    "Allen_info = df.iloc[1]\n",
    "```\n",
    "will save the 2nd row of `df` as `Allen_info`.  If we `print(Allen_info)`, we have the following key-value pairs\n",
    "```py\n",
    "Name      Allen, Mr. William Henry\n",
    "Age                             35\n",
    "Course            Machine Learning\n",
    "Name: 1, dtype: object\n",
    "```\n",
    "`Allen_info` behaves like a dictionary, for example, `Allen_info['Age']` will return `35`.\n",
    "\n",
    "\n",
    "### **Accessing a single element in a DataFrame**\n",
    "\n",
    "According to our previous discussion, there are two options to access a single element of a `DataFrame`. For example, suppose we want `Allen`'s age:\n",
    "- Taking the `'Age'` entry of the Allen row, as above: `df.iloc[1]['Age']`\n",
    "- Taking the 2nd entry of the 'Age' column: `df['Age'][1]`\n",
    "\n",
    "with both methods producing the output `35`. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try this out yourself in this cell\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Adding a new row to the DataFrame**\n",
    "\n",
    "Similar to lists, each `DataFrame` has a built-in method `append()` that can add a new row. Since the `DataFrame` has several entries, we need first to create a dictionary, which will be added to the `DataFrame`. Let us see how this work with the following example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sara_info = {'Name':'Sara Remmen', 'Age': 20, 'Course':'Python programing','Grade': 10}\n",
    "\n",
    "# Adding the new dictionary\n",
    "df2 = df.append(sara_info, ignore_index=True)\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a few things to mention:\n",
    "- We have added a new key `'Grade'` to the dictionary, which creates a new column in the DataFrame. Since previous entries do not have values for this key, they are set to `NaN` for the other rows. \n",
    "- Unlike lists, using `append()` does not modify the original DataFrame `df`. If we want to save the modified DataFrame, we need to assign `df.append()` to something, e.g., `df2`. \n",
    "\n",
    "If we want to modify `df` directly, we can use the `loc[i]` attribute, where `i` is the position we want to add the new row. Here is an example. (Note in this case, the new row must have the same number of entries as the existing DataFrame rows.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[3] = ['Nathan S.', 20, 'Julia programing']\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Changing an entry in your DataFrame**\n",
    "\n",
    "You can use `loc[row,col]` to change entries in your DataFrame, labeled by row `row` and column `col`. Here is an example where we change Allen's `Grade` from `NaN` to `8`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.loc[2,'Grade'] = 8 \n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Removing a whole row in a DataFrame**\n",
    "\n",
    "To delete a row, we use the built-in method `drop`. For instance, let us remove the entry for Sara's info from `df2`, which is labeled as row `3`. The syntax is \n",
    "```\n",
    "df3 = df2.drop(labels=3)\n",
    "```\n",
    "Note that by default `drop()` does not modify the original DataFrame, so we have assigned it to a new DataFrame `df3`. If we want to modify the original DataFrame, we set the keyword `inplace=True`, as follows:\n",
    "```py\n",
    "df2.drop(labels=3,inplace=True)\n",
    "```\n",
    "However, be careful when using this option since once rows are removed, we cannot recover them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some space to write your own code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Adding a new column to the DataFrame**\n",
    "\n",
    "To add a complete column, we use a syntax similar to dictionaries. We have to specify all the elements of the column in a list, whose length has to match the length of the `DataFrame`. In our previous examples we would have made.\n",
    "\n",
    "```py\n",
    "df2['Major'] =  ['Physics and Astronomy', 'Computer Science', 'Physics and Astronomy', 'Maths']\n",
    "\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#some space for coding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging two (or more) DataFrames\n",
    "One of the main advantages of **pandas** is that it offers high performance merging and joining of data sets with the same number of columns. Let's see it in an specific example. (Note that the `ignore_index=True` keyword is needed to ignore previous row labels and relabel the indices of the rows in the merged DataFrame.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.concat([df,df2],ignore_index=True)\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Loading and saving DataFrames**\n",
    "\n",
    "A `csv` file, which stands for Comma Separated Values, is a useful format for storing small-to-medium-sized data sets in plain text format. First, we consider loading a file and saving it to a DataFrame. The syntax for Mac and Linux is\n",
    "```py\n",
    "df = pd.read_csv(\"directory1/directory2/file_name.csv\")\n",
    "```\n",
    "and for Windows the syntax is\n",
    "```py\n",
    "df = pd.read_csv(\"directory1\\\\directory2\\\\file_name.csv\")\n",
    "```\n",
    "That is, the separator between directory names is `/` for Mac and Linux, and `\\\\` for Windows. \n",
    "\n",
    "Similarly, the syntax for saving a DataFrame is:\n",
    "```py\n",
    "df.to_csv('directory1/directory2/file_name.csv',index=False)\n",
    "\n",
    "```\n",
    "whereas for Windows the syntax is\n",
    "```py\n",
    "df.to_csv('directory1\\\\directory2\\\\file_name.csv',index=False)\n",
    "\n",
    "```\n",
    "If the entire path of directories is not specified, the file will be loaded or saved in the same folder of our jupyter notebook. The keyword `index=False` is useful, otherwise the row index is also saved in the `csv` file too.\n",
    "\n",
    "## Plotting data from DataFrames\n",
    "\n",
    "DataFrames have a built-in method `plot()` for quickly plotting the data they contain data. For more on plotting see the [Chart Visualization](https://pandas.pydata.org/pandas-docs/stable/user_guide/visualization.html).\n",
    "\n",
    "Here is an example for loading, plotting, and saving some data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, load the data and get a quick view of what it contains\n",
    "\n",
    "df = pd.read_csv('saving_example.csv')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, make a plot\n",
    "\n",
    "df.plot('x','y',kind='scatter')\n",
    "\n",
    "# Create a new column\n",
    "# Define new variable w = x*y\n",
    "\n",
    "df['w'] = df['x']*df['y']\n",
    "\n",
    "df.plot('x','w',kind='scatter')\n",
    "\n",
    "# Save the new DataFrame\n",
    "# Using the same name will overwrite the original file\n",
    "\n",
    "df.to_csv('saving_example.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3\n",
    "### Galaxy rotation curve\n",
    "\n",
    "The Directory `Rotation curves`, contains  data sets for the rotation curve for several Dwarf galaxies. See [rotation curves](https://github.com/keiwanjamaly/Python-Tutorials/blob/main/Rotation%20curves/readme.pdf) for a detail description of the data files. In this exercise we will  practice our **pandas** skills on those files (They will also be used in Tutorial 6 using **classes**, and in Tutorial 8, when we covering **function fitting**).\n",
    "\n",
    "By the end of this exercise we will obtain our Dark Matter rotation curve \n",
    "$$v_{DM}(r) = \\sqrt{v_c^2(r)-v_{star}^2(r)-v_{gas}^2(r)} \\, ,$$\n",
    "as well as our DM mass distribution \n",
    "$$M_{DM}(r) = r v^2_{DM}(r)/G_N \\, .$$\n",
    "We will take distance $r$ to be in units of kiloparsecs, velocity $v$ to be in units of km/s$, and mass $M$ in solar masses $M_\\odot$. Hence, it is useful to take Newton's gravitational constant in these units as $G_N = 4.302 \\times 10^{-6}e-6  km^2/s^2*kpc/Msol\n",
    "We will plot them having into account errors in the measurements as well as systematic errors. Let us divide the exercise in several steps.\n",
    "\n",
    "1. Choose your favorite galaxy, i.e. identify the two files `RotationCurve galaxy.csv` and `RotationCurve baryons galaxy.csv`.\n",
    "2. Create the **DataFrames** `df_circular` and `df_baryon` for each of the two data files. They should look similar to the following example for Galaxy `'IC2574'`:\n",
    "\n",
    "![](./Figures/circ_velocity.png \"Circular velocity\")\n",
    "\n",
    "\n",
    "![](./Figures/cir_vel_baryon.png \"Baryonic circular velocity\")\n",
    "\n",
    "\n",
    "3. The radial data points used in the two `DataFrames` are different and therefore we want to have the values of `gas circ velocity` and `star circ velocity` evaluated at the same radial positions as `circ velocity`. For that we need to create  **interpolating** functions for the `gas circ velocity` and `star circ velocity` data (We will cover more on interpolating functions in Tutorial 7).  Use \n",
    "```py\n",
    "from scipy.interpolate import interp1d \n",
    "```\n",
    "and then create the interpolating functions with\n",
    "```py\n",
    "stars_circ_velocity = interp1d(r_baryon,v_star,kind = 'quadratic')\n",
    "gas_circ_velocity = interp1d(r_baryon,v_gas,kind = 'quadratic')\n",
    "```\n",
    "where `r_baryon` is the list containing the radial points in `df_baryon` created in step 1. \n",
    "4. Now that we have our two interpolating functions, we can evaluate them at `r_circular`, the radial points given in `df_circular`. Add two new columns to `df_circular` containing the stars and gas circular velocities evaluated at  `r_circular`. At this stage our `df_circular` should look like\n",
    "\n",
    "![](./Figures/step_4.png)\n",
    "\n",
    "5. As explained in [rotation curves](https://github.com/keiwanjamaly/Python-Tutorials/blob/main/Rotation%20curves/readme.pdf), some of the measured errors (i.e. some values in `circ velocity error`) have been underestimated. In this step we will  include a systematic error at the level of 5% of the last measured velocity point (i.e. the last data point of column `cir velocity` in our `df_circular`). Add a new column in `df_circular` called `syst error` whose values contain the systematic error. Then, add a new column  `total error`, containing the total error computed as the sum in quadratures of `sys error` and   `circ velocity error`. After this step, our `df_circular` should look like\n",
    "\n",
    "![](./Figures/step_5.png)\n",
    "\n",
    "6. Let us now add a column with the DM velocity, which is computed from $$v_{DM}(r) = \\sqrt{v_c^2(r)-v_{star}^2(r)-v_{gas}^2(r)},$$ We have to be careful however, since $v_{DM}^2(r)$ could be negative, if that is the case,  we choose to change sign of $v_{gas}^2(r)$.  Similarly, compute $M_{DM}(r)$ and add it as new column. After this steps,  our `df_circular` should look like:\n",
    "\n",
    "![](./Figures/step_6.png)\n",
    "\n",
    "7. Plot $v_{DM}(r)$ including error bar given by the `total error` column.  (hint: use the `errorbar` plotting function in `matplotlib`)\n",
    "8. Plot $M_{DM}(r)$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
