{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 8\n",
    "\n",
    "**Authors:**\n",
    "* Yilber Fabian Bautista\n",
    "* \n",
    "\n",
    "**Last date of modification:**\n",
    " December 29th 2021\n",
    "\n",
    "Hello there, \n",
    "\n",
    "Welcome to Lecture 8 of this mini-lecture series on programing with Python. In this series, you will learn  basic and intermediate python tools that will be of great use in your scientific carer\n",
    "\n",
    "**Objectives:** \n",
    "\n",
    "By the end of this lecture you will be able to:\n",
    "* Create, modify, save, and interact with **HDF5** files\n",
    "* **Fit** curves to a given set of data points using **curve_fit** module in ** scipy.optimize** library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HDF5 files\n",
    "\n",
    "See documentation [here](https://docs.h5py.org/en/stable/quick.html).\n",
    "\n",
    "**HDF** stands for “Hierarchical Data Format”. An HDF5 file contains two kinds of objects: `datasets`, which are **array-like** collections of data, and ` groups`, which are **folder-like** containers that hold datasets and other groups. Schematically, an **HDF5** file looks as follows\n",
    "\n",
    "<img src=\"Figures/HDF5_gen.png\" width=\"600\" height=\"400\">\n",
    "\n",
    "\n",
    "Figure taken from [here](https://icmplus.neurosurg.cam.ac.uk/home/icm-features/hdf5-new-icm-data-format/).\n",
    "The Groups and datasets can be further commentated with **metadata**  contained in associated **Attributes**. We will expand on this bellow. \n",
    "\n",
    "The fundamental thing to have in mind when dealing with **HDF5** files is: **Groups** are used  like **dictionaries**, whereas **datasets** work like **NumPy arrays**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Opening  HDF5 files\n",
    "\n",
    "Let us suppose someone handled us an `HDF5` file and we want to use it. \n",
    "First we have to import the `h5py` library in python to manipulate such a file. This is done through the command\n",
    "```py\n",
    "import h5py\n",
    "````\n",
    "To open our existing `HDF5` file we have two options:\n",
    "\n",
    " * The syntax for the first one is:\n",
    "\n",
    "```py\n",
    "f = h5py.File('myfile.hdf5','r')\n",
    "# Do something\n",
    "\n",
    "f.close()\n",
    "\n",
    "```\n",
    "Here the `close()` attribute closes the `HDF5` file if no longer needed. \n",
    "\n",
    "* The second option is via a `with` block:\n",
    "\n",
    "```py\n",
    "with h5py.File('myfile.hdf5', 'r') as f:\n",
    "    # Do something\n",
    "        \n",
    "```\n",
    "For this second method, to close the  `HDF5` file we just need to leave the `with` block.\n",
    "\n",
    "The keyword `r` stands for `read`, which means we can only read but not modify the `HDF5` file. In the next table we can see other keywords commonly used when dealing with data files. We will use some of them bellow\n",
    "<img src=\"Figures/rwa.png\" width=\"600\" height=\"400\">\n",
    "\n",
    "\n",
    "Let us make the discussion more precise with the following example:\n",
    "\n",
    "We are handled the `mytestfile.hdf5` file and we want to access all the information contained inside it. We start by opening the file using the ` h5py` library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "# Open a hdf5 file\n",
    "f = h5py.File('mytestfile.hdf5','r')\n",
    "\n",
    "# Close the file if no longer needed\n",
    "#f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keys of a HDF5 file\n",
    "\n",
    "Likewise for dictionaries,  we can as for the set of keys contained in the file if not known beforehand, using the attribute `keys()`: \n",
    "```py\n",
    "f.keys()\n",
    "```\n",
    "which will produce the output\n",
    "```py\n",
    "<KeysViewHDF5 ['mydataset', 'mygroup']>\n",
    "```\n",
    "This means our `HDF5` file has two objects labeled by the keys `'mydataset'` and  `'mygroup'`. In principle they can correspond to either **datasets** or **groups** of our `HDF5` file. \n",
    "\n",
    "### Accessing a group or data set \n",
    "To explicitly know the nature of the two keys in our example, we need to call our file `f` with the specific key using an dictionary-like syntax:\n",
    "```py\n",
    "f['mydataset']\n",
    "```\n",
    "with output \n",
    "\n",
    "```py\n",
    "<HDF5 dataset \"mydataset\": shape (20,), type \"<i4\">\n",
    "```\n",
    "Therefore,  `\"mydataset\"` indeed corresponds to a **dataset** in the `HDF5` file. It is a row vector with 20 entries, whose elements are  integers. \n",
    "\n",
    "We can do the same for the remaining key\n",
    "```py\n",
    "f['mygroup']\n",
    "```\n",
    "with output \n",
    "```py\n",
    "<HDF5 group \"/mygroup\" (1 members)>\n",
    "```\n",
    "This means that `mygroup` corresponds instead to a **group** in our  `HDF5` file, and hosts another element which can be either a **dataset** or a **group**. Recall **groups** are like **dictionaries**, and therefore, the logic to access the keys for the elements contained in the group is the same,  that is, by using the `key()` attribute. \n",
    "```py\n",
    "f['mygroup'].keys()\n",
    "```\n",
    "with output \n",
    "```py\n",
    "<KeysViewHDF5 ['newdataset']>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try it yourself"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing the information in a dataset \n",
    "\n",
    "Now that we know how to ask for the keys in a `HDF5` file, and access the groups and datasets inside them, we want to be able to use the information stored in the datasets themselves. Recall **datasets** are like **np.arrays**, and therefore we can use all of the numpy machinery on them. Let us see that with the dataset contained in `'mydataset'` keyword in our previous example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 75, 80,\n",
       "       85, 90, 95], dtype=int32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = f['mydataset']\n",
    "data[:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can for instance slice the array,\n",
    "```py\n",
    "data[2:-3]\n",
    "```\n",
    "or even plot it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f4640a68050>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXhU5d3G8e/DEiAsgRCWsISwQyBhMSyCVVSqCBRE6taquBW7vV3eVgiCijuirbVVq2i12tpWJayCiqKodUGBQhKyQAgBAiEJS0gge+Z5/8jYl6YJDGQmJzNzf64rVyYzZzy3Jyc3JydzfmOstYiIiP9p5nQAERE5PypwERE/pQIXEfFTKnARET+lAhcR8VMtGnNlERERNjo6ujFXKSLi97Zu3XrEWtul9v2NWuDR0dFs2bKlMVcpIuL3jDH76rpfp1BERPyUClxExE+pwEVE/JQKXETET6nARUT8lApcRMRPqcBFRPyUClxExIeOn6rggbU7KSqr9Pp/u1Ev5BERCRbWWtYnH+b+NSkUllQysX8Ek2O6eXUdKnARES/LLypj0aoUNqTmEdszjL/cMY6hkR28vh4VuIiIl1hreWtLDg+tS6WiysWCq4Zwx0V9adHcN2erVeAiIl6w/2gJC1Ym8VnmUcb2Defx2XH0jWjr03WqwEVEGqDaZfnz59k8+V4GzZsZHr56ON8bG0WzZsbn61aBi4icp915xcxLTOJf+wu5dHAXHpkVS4+ObRpt/SpwEZFzVFHl4vmP9/DMh5m0bdWc310/kpkje2CM74+6T6cCFxE5B0k5hcxbnkT64WK+M6IH938nhoh2rRzJogIXEfFAaUU1v/tgFy9+mkWX9q148ZZ4vu3l13WfKxW4iMhZfJl1lITEJLKPlnDj2N4smDqUDq1bOh1LBS4iUp/iskqWvJPO65v3ExUeyt/uHMeEARFOx/o3FbiISB0+TM9j4coU8orKuPOivvzqisG0CWnudKz/oAIXETnN0ZPlPPh2Kqu3H2JQt3Y89/0JjIrq5HSsOqnARUSouQx+bVIui9fspLiskl9MHsiPJw0gpEXTHdqqAheRoHf4RBmLViXzQVo+I3p3ZOnsOAZ3b+90rLNSgYtI0LLW8o+vD/DoujQqXS4WTRvKbRP70rwRLoP3BhW4iASlfUdPkZCYzBdZR7mwX2eWzI6lT2ffDp/yNhW4iASVapfl5X/u5TfvZ9CyWTOWXBPL9WN6N/pl8N6gAheRoJFxuJh5y3ewI+cEk4d25eGrY+ke1trpWOdNBS4iAa+iysWzH2Xy3KZMOrRuyR9uHMX0uEi/POo+nQpcRALa9gOFzFu+g115J7l6ZA/u+84wwtuGOB3LK1TgIhKQSiqq+O2GXbz82V66dWjNy7fGc9kQZ4dPeZsKXEQCzueZR0hYkcz+YyXcND6K+VOG0L4JDJ/yNhW4iASME6WVPLY+jX98fYDozqH8Y+54xvfr7HQsn1GBi0hAeD81j0WrkikoLueuS/rxy8mDaN2yaQ2f8jYVuIj4tSMny1m8ZidvJ+UypHt7XrwlnrheHZ2O1ShU4CLil6y1rNp+kAfWplJSXs2vvj2Iuy7p36SHT3mbClxE/M6hwlIWrkzmo4wCRkXVDJ8a2K3pD5/yNo8K3BjzS+BOwALJwG1AKPAGEA1kA9dZa4/7JKWICOByWV7/aj+Pv5NOtcty3/QY5kyI9pvhU9521gI3xvQEfgbEWGtLjTFvAjcAMcBGa+0SY0wCkADM92laEQlaWQUnSViRzFd7jzFxQGcemxVHVOdQp2M5ytNTKC2ANsaYSmqOvA8BC4BJ7sdfBTahAhcRL6uqdvHSP/fy1Pu7CGnRjKWz47g2vpffXwbvDWctcGvtQWPMk8B+oBTYYK3dYIzpZq3NdS+Ta4zpWtfzjTFzgbkAUVFR3ksuIgEv9VAR8xJ3kHKwiCtiuvHQ1cPp1sF/h095myenUDoBM4G+QCHwljHmJk9XYK1dBiwDiI+Pt+eZU0SCSHlVNc98mMkfN+2hY2hLnvneKKbF+v/wKW/z5BTKZGCvtbYAwBizApgA5BljIt1H35FAvg9zikiQ2LrvOPMTk8jMP8k1o3ty77QYOgXI8Clv86TA9wPjjTGh1JxCuRzYApwC5gBL3J9X+yqkiAS+U+VVPLkhgz9/nk1kh9a8ctsYLh1c55lZcfPkHPhmY8xyYBtQBfyLmlMi7YA3jTF3UFPy1/oyqIgErk93F7BgRTI5x0u55cI+zJsyhHatdJnK2Xi0hay19wP317q7nJqjcRGR83KipJJH1qfy5pYc+kW05c27LmRs33CnY/kN/RMnIo54N+Uw965O4dipCn40qT8/v3xgwA+f8jYVuIg0qoLimuFT65JziYnswCu3jmF4zzCnY/klFbiINAprLSu2HeTBt1Mprazm7isHM/fifrRsHjzDp7xNBS4iPpdzvIR7Vqbwya4CLujTicdnxzGgazunY/k9FbiI+IzLZfnr5n08/k46FnhgxjBuHt+HZkE6fMrbVOAi4hN7Ck6SkJjE19nH+dbACB6dFUvv8OAePuVtKnAR8arKahcvfprF7z7YTZuWzXny2hHMHt1Tl8H7gApcRLwm5eAJ5icmsfNQEVNju7N4xjC6ttfwKV9RgYtIg5VVVvP7jbt54ZMsOoWG8PxNo5kyPNLpWAFPBS4iDbIl+xjzEpPIKjjFtRf0YtG0GMJCWzodKyiowEXkvJwsr+KJd9N57ct99Ahrw2u3j+XiQV2cjhVUVOAics4+3lXAPSuSOXSilDkXRnP3lYNpq+FTjU5bXEQ8VlhSwYNvp7Ji20H6d2nL8h9eyAV9NHzKKSpwEfHI+uRc7ludQmFJJT+9dAA/vWyAhk85TAUuImeUX1TGfat38u7Owwzv2YFXbx/LsB4aPtUUqMBFpE7WWt7amsPDb6dSVuVi/pQh/OBbfWmh4VNNhgpcRP7LgWMl3LMymU93H2FsdDhLZsfSr4uGTzU1KnAR+bdql+W1L7J54r0MDPDQ1cP5/tgoDZ9qolTgIgJAZn4x85YnsW1/IZMGd+GRWbH07NjG6VhyBipwkSBXWe3ihY/38PuNmYS2as5T14/g6pEaPuUPVOAiQSw55wR3L99B+uFipsVF8sCMYUS0a+V0LPGQClwkCJVVVvO7D3bz4qdZdG4bwgs3X8CVw7o7HUvOkQpcJMhszjpKwopk9h45xfXxvbln2lDC2mj4lD9SgYsEieKySpa+m8FfvtxH7/A2vH7nOCYOiHA6ljSAClwkCHyUkc/CFcnkFpVx+8S+/PrKQYSG6Mff3+k7KBLAjp+q4KG3U1nxr4MM7NqOxB9NYHRUJ6djiZeowEUCkLWWdcm53L96JydKK/nZZQP4yWUDaNVCw6cCiQpcJMDkFZWxaFUK76fmEdcrjL/eOY6hkR2cjiU+oAIXCRDWWt7ccoCH16VRUeXinqlDuH2ihk8FMhW4SADYf7SEhBVJfL7nKOP6hvP47DiiI9o6HUt8TAUu4seqXZZXPtvLbzbsonkzwyOzhnPjGA2fChYqcBE/tSuvZvjU9gOFXDakK4/MGk5kmIZPBRMVuIifqahy8cdNe3jmo920b92Sp28YyYwRPTR8Kgh5VODGmI7AS8BwwAK3AxnAG0A0kA1cZ6097pOUIgLAjgOFzE9MIv1wMTNG9OD+78TQWcOngpanf55+GnjXWjsEGAGkAQnARmvtQGCj+2sR8YHSimoeXZ/GrOc+o7Ckkpduief3N45SeQe5sx6BG2M6ABcDtwJYayuACmPMTGCSe7FXgU3AfF+EFAlmX+w5yoIVSWQfLeF746JIuGoIHVpr+JR4dgqlH1AAvGKMGQFsBX4OdLPW5gJYa3ONMV3rerIxZi4wFyAqKsoroUWCQVFZJY+tT+fvX+2nT+dQ/vaDcUzor+FT8v88KfAWwGjgf6y1m40xT3MOp0ustcuAZQDx8fH2vFKKBJmNaXksXJlCfnEZcy/uxy8nD6JNiC6Dl//kSYHnADnW2s3ur5dTU+B5xphI99F3JJDvq5AiweLoyXIeWJvKmh2HGNytPc/ffAEje3d0OpY0UWctcGvtYWPMAWPMYGttBnA5kOr+mAMscX9e7dOkIgHMWsuaHYd4YG0qxWWV/HLyIH40qT8hLXQZvNTP09eB/w/wujEmBMgCbqPmFSxvGmPuAPYD1/omokhgyz1RyqKVKWxMz2dk744s/W4cg7q1dzqW+AGPCtxaux2Ir+Ohy70bRyR4uFyWv3+9n8fWp1PlcrFo2lBum9iX5roMXjykKzFFHJB95BQJK5L4MusYE/p3Zsk1cUR1DnU6lvgZFbhII6qqdvGye/hUSPNmLLkmluvH9NZl8HJeVOAijSQtt4j5iUkk5Zxg8tBuPHz1cLqHtXY6lvgxFbiIj5VXVfPsR3t47qNMwtq05A83jmJ6XKSOuqXBVOAiPrRt/3HmL09id/5JZo3qyb3TYwhvG+J0LAkQKnARHyipqOI3G3bx8md76d6hNa/cOoZLh9Q5bULkvKnARbzss8wjJKxI4sCxUm4aH8X8KUNor+FT4gMqcBEvOVFayWPr0/jH1wfoG9GWN+aOZ1y/zk7HkgCmAhfxgg07D7NoVQpHTpZz1yU1w6dat9TwKfEtFbhIAxQUl7N47U7WJeUypHt7XpoTT1wvDZ+SxqECFzkP1lpWbT/IA2tTKSmv5lffHsQPJ/WnZXMNn5LGowIXOUcHC0tZuDKZTRkFjIrqyNLZcQzU8ClxgApcxEMul+X1r/azZH0aLgv3TY9hzoRoDZ8Sx6jARTyQVXCShMRkvso+xkUDInjsmlh6h2v4lDhLBS5yBlXVLl76516een8XIS2asXR2HNfG99Jl8NIkqMBF6pF6qIh5iTtIOVjEFTHdeOjq4XTroOFT0nSowEVqKa+q5pkPM/njpj10DG3Jc98fzVXDu+uoW5ocFbjIabbuO8b8xGQy809yzeie3Dsthk4aPiVNlApcBDhVXsUT72Xw6hfZ9Ahrw59vG8OkwRo+JU2bClyC3qe7C1iwIpmc46XccmEf5k0ZQrtW+tGQpk97qQStEyWVPLwulbe25tAvoi1v3nUhY/uGOx1LxGMqcAlK76Yc5t7VKRw7VcGPJ/XnZ5cP1PAp8TsqcAkq+cVlLF6zk/XJh4mJ7MArt45heM8wp2OJnBcVuAQFay0rth3kwbdTKa2s5u4rBzP34n4aPiV+TQUuAS/neAn3rEzhk10FxPfpxJLZcQzo2s7pWCINpgKXgOVyWf7y5T4efzcdgAdmDOPm8X1opuFTEiBU4BKQ9hScZP7yJLbsO87Fg7rw6Kzh9Oqk4VMSWFTgElAqq10s+ySLpzfupk3L5jx57Qhmj+6py+AlIKnAJWCkHDzB/MQkdh4qYmpsdxbPGEbX9ho+JYFLBS5+r6yymt9v3M0Ln2TRKTSE528azZThkU7HEvE5Fbj4tS3Zx5iXmERWwSmuvaAXi6bFEBba0ulYIo1CBS5+6WR5FU+8m85rX+6jR1gbXrt9LBcP6uJ0LJFGpQIXv/PxrgLuWZHMoROlzLkwmruvHExbDZ+SIOTxXm+MaQ5sAQ5aa6cbY8KBN4BoIBu4zlp73BchRQAKSyp46O00Erfl0L9LW5b/8EIu6KPhUxK8zuU64p8Daad9nQBstNYOBDa6vxbxiXeSc5n8209Yvf0gP710AOt+9i2VtwQ9j47AjTG9gGnAI8D/uu+eCUxy334V2ATM9248CXb5RWXct3on7+48zPCeHXj19jEM66HhUyLg+SmU3wHzgPan3dfNWpsLYK3NNcbU+fYlxpi5wFyAqKioBkSVYGKt5a2tOTz8diplVS7mTxnCD77VlxYaPiXyb2ctcGPMdCDfWrvVGDPpXFdgrV0GLAOIj4+355xQgs6BYyXcszKZT3cfYWx0OEtmx9Kvi4ZPidTmyRH4RGCGMWYq0BroYIz5K5BnjIl0H31HAvm+DCqBr9plee2LbJ54LwMDPDRzGN8fp+FTIvU5a4FbaxcACwDcR+C/ttbeZIx5ApgDLHF/Xu3DnBLgMvOLmbc8iW37C5k0uAuPzIqlZ8c2TscSadIa8uLZJcCbxpg7gP3Atd6JJMGkstrFCx/v4fcbMwlt1Zynrh/B1SM1fErEE+dU4NbaTdS82gRr7VHgcu9HkmCRnHOCu5fvIP1wMdPiInlgxjAi2rVyOpaI39Dla9LoyiqreeqDXbz06V46tw3hhZsv4Mph3Z2OJeJ3VODSqDZnHSVhRTJ7j5zihjG9WTB1KGFtNHxK5HyowKVRFJdV8vi76fz1y/30Dm/D63eOY+KACKdjifg1Fbj43Efp+dyzMpnDRWXccVFffnXFIEJDtOuJNJR+isRnjp2q4MG1O1m1/RADu7Yj8UcTGB3VyelYIgFDBS5eZ63l7aRcFq/ZyYnSSn52+UB+cml/WrVo7nQ0kYCiAhevyisqY+HKFD5IyyOuVxh/vXMcQyM7OB1LJCCpwMUrrLW88fUBHlmfRkWVi4VTh3LbxGgNnxLxIRW4NNi+o6dISEzmi6yjjOsbzuOz44iOaOt0LJGApwKX81btsrzy2V6e3JBBi2bNeHRWLDeM6a3hUyKNRAUu5yXjcDHzEpPYcaCQy4Z05ZFZw4kM0/ApkcakApdzUlHl4rlNmTz7USbtW7fk6RtGMmNEDw2fEnGAClw8tv1AIfOXJ5GRV8yMET24/zsxdNbwKRHHqMDlrEorqvnt+xn86Z976dq+NS/dEs/kmG5OxxIJeipwOaPP9xwhITGZ/cdK+N64KBKuGkKH1ho+JdIUqMClTkVllTy2Pp2/f7WfPp1D+dsPxjGhv4ZPiTQlKnD5Lx+k5rFwVTIFxeXMvbgfv5w8iDYhugxepKlRgcu/HT1ZzuK1qazdcYjB3drzws3xjOzd0elYIlIPFbhgrWXNjkMsXrOTk+VV/HLyIH40qT8hLXQZvEhTpgIPcocKS1m0KoUP0/MZ0bsjS2fHMbh7e6djiYgHVOBByuWy/P3r/Ty2Pp0ql4tF04Zy28S+NNdl8CJ+QwUehPYeOUVCYhKb9x7jwn6dWTI7lj6dNXxKxN+owINIVbWLlz/by2827CKkeTOWXBPL9WN66zJ4ET+lAg8SablFzE9MIinnBJOHduPhq4fTPay107FEpAFU4AGuvKqaZz/M5LlNewhr05I/3DiK6XGROuoWCQAq8AC2bf9x5i9PYnf+SWaN6sm902MIbxvidCwR8RIVeAAqqajiyfd28crne+neoTUv3xrPZUM0fEok0KjAA8xnmUdIWJHEgWOl3DQ+ivlThtBew6dEApIKPECcKK3k0XVpvLHlAH0j2vLG3PGM69fZ6Vgi4kMq8ACwYedhFq1K4cjJcu66pGb4VOuWGj4lEuhU4H6soLicxWt3si4plyHd2/PSnHjiemn4lEiwUIH7IWstq7Yf5IG1qZSUV/PrKwZx1yX9adlcw6dEgslZC9wY0xt4DegOuIBl1tqnjTHhwBtANJANXGetPe67qAJwsLCUhSuT2ZRRwOiojiz9bhwDumr4lEgw8uQIvAr4lbV2mzGmPbDVGPM+cCuw0Vq7xBiTACQA830XNbi5XJbXN+9jyTvpuCzcNz2GOROiNXxKJIidtcCttblArvt2sTEmDegJzAQmuRd7FdiECtwnsgpOkpCYzFfZx7hoQASPXRNL7/BQp2OJiMPO6Ry4MSYaGAVsBrq5yx1rba4xpms9z5kLzAWIiopqSNagU1Xt4sVP9/LUB7to3aIZS78bx7UX9NJl8CICnEOBG2PaAYnAL6y1RZ6WiLV2GbAMID4+3p5PyGCUeqiIeYk7SDlYxJXDuvHQzOF07aDhUyLy/zwqcGNMS2rK+3Vr7Qr33XnGmEj30XckkO+rkMGkrLKaZz7M5PmP99AxNIQ/fn80V8VGOh1LRJogT16FYoA/AWnW2t+e9tAaYA6wxP15tU8SBpGt+44xb3kSewpOMXt0L+6dPpSOoRo+JSJ18+QIfCJwM5BsjNnuvu8eaor7TWPMHcB+4FrfRAx8p8qreOK9DF79IpseYW149faxXDKoi9OxRKSJ8+RVKP8E6jvhfbl34wSfT3YVsGBFModOlHLL+D7cPWUI7Vrp+ioROTs1hUMKSyp4eF0ay7fm0K9LW96860LGRIc7HUtE/IgK3AHvJOdy7+qdHC+p4CeX9ud/Lhuo4VMics5U4I0ov7iM+1fv5J2Uwwzr0YFXbx/DsB5hTscSET+lAm8E1lqWb83h4XVplFZWM2/KYH7wrX4aPiUiDaIC97EDx0q4Z2Uyn+4+wpjoTiyZHUf/Lu2cjiUiAUAF7iMul+W1L7JZ+l4GBnhw5jBuGteHZho+JSJeogL3gcz8YuYnJrN133EuGdSFR2YNp1cnDZ8SEe9SgXtRZbWLZZ9k8fQHuwlt1ZzfXjeCWaN6aviUiPiECtxLUg6eYN7yJFJzi5gWG8niGcPo0r6V07FEJICpwBuorLKapzfuZtknWYS3DeH5my5gyvDuTscSkSCgAm+Ar7OPMX95EllHTnFdfC8WTo0hLLSl07FEJEiowM/DyfIqlr6bzmtf7KNXpzb89Y5xXDQwwulYIhJkVODn6KOMfBauSCa3qIzbJkbz6ysG01bDp0TEAWoeDx0/VcFDb6ey4l8HGdC1Hct/OIEL+nRyOpaIBDEV+FlYa1mffJj716RQWFLJzy4bwE8uG0CrFho+JSLOUoGfQX5RGYtWpbAhNY/YnmG8dvs4Ynp0cDqWiAigAq+TtZa3tuTw0LpUKqpcLLhqCHdc1JcWGj4lIk2ICryW/Udrhk/9M/MIY/uGs+SaWPpp+JSINEEqcLdql+XPn2fz5HsZNG9mePjq4XxvbJSGT4lIk6UCB3bnFTMvMYl/7S9k0uAuPDorlh4d2zgdS0TkjIK6wCuqXDz/8R6e+TCTtq2a87vrRzJzZA8NnxIRvxC0BZ6UU8i85UmkHy5melzN8KmIdho+JSL+I+gKvKyymqfe38WLn2YR0a4Vy26+gCuGafiUiPifoCrwL7OOkpCYRPbREm4c25uEq4YS1kbDp0TEPwVFgReXVbLknXRe37yfqPBQ/nbnOCYM0PApEfFvAV/gH6bnsXBlCnlFZdx5UV/+94pBhIYE/P+2iASBgG2yY6cqeHDtTlZtP8TAru147kcTGBWl4VMiEjgCrsCttaxNymXxmp0UlVby88sH8uNL+2v4lIgEnIAq8MMnaoZPfZCWR1yvMJb+YBxDumv4lIgEpoAocGst//j6AI+uS6Oi2sXCqUO5bWK0hk+JSEDz+wLfd/QUCYnJfJF1lHF9w3l8dhzREW2djiUi4nN+W+DVLssrn+3lyQ0ZtGzWjEdnxXLDmN4aPiUiQcMvCzzjcM3wqR0HCrl8SFcenjWcyDANnxKR4NKgAjfGTAGeBpoDL1lrl3glVT0qqlw8tymTZz/KpH3rljx9w0hmjNDwKREJTudd4MaY5sCzwLeBHOBrY8waa22qt8KdbvuBQuYvTyIjr5iZI3tw3/QYOmv4lIgEsYYcgY8FMq21WQDGmH8AMwGvF/gfNu7mqQ920bV9a166JZ7JMd28vQoREb/TkALvCRw47escYFzthYwxc4G5AFFRUee1oqjOoVw/JooFU4fQobWGT4mIQMMKvK4Tz/a/7rB2GbAMID4+/r8e98TMkT2ZObLn+TxVRCRgNeRKlxyg92lf9wIONSyOiIh4qiEF/jUw0BjT1xgTAtwArPFOLBEROZvzPoVira0yxvwUeI+alxG+bK3d6bVkIiJyRg16Hbi1dj2w3ktZRETkHGjak4iIn1KBi4j4KRW4iIifUoGLiPgpY+15XVtzfiszpgDYd55PjwCOeDGOtylfwyhfwyhfwzXljH2stV1q39moBd4Qxpgt1tp4p3PUR/kaRvkaRvkazh8y1qZTKCIifkoFLiLip/ypwJc5HeAslK9hlK9hlK/h/CHjf/Cbc+AiIvKf/OkIXERETqMCFxHxU02uwI0xU4wxGcaYTGNMQh2PG2PM792PJxljRjditt7GmI+MMWnGmJ3GmJ/XscwkY8wJY8x298d9jZXPvf5sY0yye91b6njcye03+LTtst0YU2SM+UWtZRp1+xljXjbG5BtjUk67L9wY874xZrf7c6d6nnvGfdWH+Z4wxqS7v38rjTEd63nuGfcFH+ZbbIw5eNr3cGo9z3Vq+71xWrZsY8z2ep7r8+3XYNbaJvNBzVjaPUA/IATYAcTUWmYq8A417wg0HtjciPkigdHu2+2BXXXkmwS87eA2zAYizvC4Y9uvju/1YWouUHBs+wEXA6OBlNPuWwokuG8nAI/Xk/+M+6oP810BtHDffryufJ7sCz7Mtxj4tQfff0e2X63HfwPc59T2a+hHUzsC//cbJVtrK4Bv3ij5dDOB12yNL4GOxpjIxghnrc211m5z3y4G0qh5b1B/4tj2q+VyYI+19nyvzPUKa+0nwLFad88EXnXffhW4uo6nerKv+iSftXaDtbbK/eWX1LwbliPq2X6ecGz7fcMYY4DrgL97e72NpakVeF1vlFy7ID1ZxueMMdHAKGBzHQ9faIzZYYx5xxgzrFGD1bwv6QZjzFb3G0rX1iS2HzXv4FTfD46T2w+gm7U2F2r+0Qa61rFMU9mOt1PzG1VdzrYv+NJP3ad4Xq7nFFRT2H7fAvKstbvredzJ7eeRplbgnrxRskdvpuxLxph2QCLwC2ttUa2Ht1FzWmAE8AdgVWNmAyZaa0cDVwE/McZcXOvxprD9QoAZwFt1POz09vNUU9iOC4Eq4PV6FjnbvuArfwT6AyOBXGpOU9Tm+PYDbuTMR99ObT+PNbUC9+SNkh19M2VjTEtqyvt1a+2K2o9ba4ustSfdt9cDLY0xEY2Vz1p7yP05H1hJza+qp2sKb0Z9FbDNWptX+wGnt59b3jenldyf8+tYxun9cA4wHfi+dZ+wrc2DfcEnrLV51tpqa60LeLGe9Tq9/VoA1wBv1LeMU9vvXDS1AvfkjZLXALe4X00xHjjxza+7vuY+Z/YnIM1a+9t6lunuXg5jzFhqtvHRRsrX1hjT/pvb1PyxK6XWYo5tv5cs2ssAAAEPSURBVNPUe+Tj5PY7zRpgjvv2HGB1Hcs49qbexpgpwHxghrW2pJ5lPNkXfJXv9L+pzKpnvU6/KfpkIN1am1PXg05uv3Pi9F9Ra39Q8yqJXdT8hXqh+74fAj903zbAs+7Hk4H4Rsx2ETW/5iUB290fU2vl+ymwk5q/qn8JTGjEfP3c693hztCktp97/aHUFHLYafc5tv2o+YckF6ik5qjwDqAzsBHY7f4c7l62B7D+TPtqI+XLpOb88Tf74PO189W3LzRSvr+4960kako5siltP/f9f/5mnztt2Ubffg390KX0IiJ+qqmdQhEREQ+pwEVE/JQKXETET6nARUT8lApcRMRPqcBFRPyUClxExE/9H/USeSAB3vHRAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "plt.plot(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, one  can now ask how to access the dataset contained in the group `'mygroup'`. For that we have several options:\n",
    "* By assigning a new variable to `f['mygroup']`, and then accessing `'newdataset'` using it as a keyword\n",
    "```py\n",
    "grp = f['mygroup']\n",
    "dset = grp['newdataset']\n",
    "dset\n",
    "```\n",
    "with output \n",
    "\n",
    "```py\n",
    "<HDF5 dataset \"newdataset\": shape (), type \"<f8\">\n",
    "```\n",
    "That means that `dset` is a scalar (shape() array), and therefore to access it we use the syntax\n",
    "```py\n",
    "dset[()]\n",
    "```\n",
    "which will produce as output the float number `50.0`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try it yourself"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We avoid too many variable assignation we can simply use repeated indexing\n",
    "```py\n",
    "dset = f['mygroup']['newdataset']\n",
    "```\n",
    "which will have the same effect. \n",
    "\n",
    "* To avoid too many square brackets we can simply use a path-like argument:\n",
    "```py\n",
    "dset = f['/mygroup/newdataset'][()]\n",
    "dset\n",
    "```\n",
    "where we have already  accessed the scalar element, getting as output the number `50.0`.  This is the path specification for Mac and Linux. For windows you will probably have to use\n",
    "```py\n",
    "dset = f['\\\\mygroup\\\\newdataset'][()]\n",
    "dset\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#try it yourself"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then see that it is very simple to navigate through the `HDF5` file by using keyword arguments. \n",
    "\n",
    "### Attributes of  groups and data sets\n",
    "The last element to explore in our `HDF5` file is to ask for the **Metadata** stored in **attributes** of the `HDF5` file itself, groups and datasets.  For that we use the `.attrs` proxy. See [documentation](https://docs.h5py.org/en/stable/high/attr.html#h5py.AttributeManager.keys). Let us see for instance if our `HDF5` has attribute keywords:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KeysViewHDF5 []>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.attrs.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the output is an empty list meaning that the file itself does not have attribute keywords. We can ask the same for the groups and datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KeysViewHDF5 ['new_atribute']>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f['mygroup'].attrs.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in this case, the group itself has an attribute given by the keyword `'new_atribute'`. We can access its content in the usual indexing-like form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f['mygroup'].attrs['new_atribute']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see, the attribute just has assigned the integer value 10.  You can check that the datasets do not have any attribute by using the same logic\n",
    "```py\n",
    "f['mygroup/newdataset'].attrs.keys()\n",
    "```\n",
    "and \n",
    "```\n",
    "f['mydataset'].attrs.keys()\n",
    "```\n",
    "both of which produce as output an empty list.\n",
    "\n",
    "Attributes have the following properties as specified in the [documentation](https://docs.h5py.org/en/stable/high/attr.html#h5py.AttributeManager.keys)\n",
    "\n",
    "* They may be created from any scalar or NumPy array\n",
    "* Each attribute should be small (generally < 64k)\n",
    "* There is no partial I/O (i.e. slicing); the entire attribute must be read."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Closing the `HDF5` file\n",
    "\n",
    "Once we finish using the file we can simply close it using the `close()` attribute. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1\n",
    "Repeat the all the above discussion but opening the file using a `with` block. Hint: use the `'r'` argument, and recall indentation is important.  `print` statements are also useful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating an HDF5 file\n",
    "\n",
    "We might now wonder how was `mytestfile.hdf5` file created. We simply used the following code:\n",
    "```py\n",
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "with h5py.File('mytestfile.hdf5', 'w') as g:\n",
    " \n",
    "    dset = g.create_dataset(\"mydataset\", (20,),data = np.arange(0,100,5), dtype='i')\n",
    "    grp2 = g.create_group('mygroup')\n",
    "    dset2 = grp2.create_dataset(\"newdataset\", data = 50.)\n",
    "    grp2.attrs['new_atribute'] = 1.0\n",
    "```\n",
    "which we will proceed to explain in detail. \n",
    "\n",
    "1. The first step is of course to create the datafile with the given name, in this case `mytestfile.hdf5`, and use the `'w'` (write) keyword, as indicated in the table above. We create the file under the alias `g`. Up to here, a new `HDF5` file will be created in the same location of our notebook. (To specify a particular location we use the path for it. example: `with h5py.File('Documents/my_files/Explore/.../mytestfile.hdf5', 'w') as g` ). The newly created file will be an empty file which we then proceed to fill with **groups** and **datasets**\n",
    "\n",
    "2. In the first indented line ` dset = g.create_dataset(\"mydataset\", (20,),data = np.arange(0,100,5), dtype='i')` we have created a new dataset, whose keyword is `\"mydataset\"`. It contain a vector with 20 entries, given by the `20` elements of the array `np.arange(0,100,5)`. We further specified the data type using the ` dtype` keyword.  \n",
    "3. In the second line `grp2 = g.create_group('mygroup')`, we simply added a new group, as clearly indicated by the syntax. \n",
    "4. In the next line we have added a new dataset to our existing group, where now the data corresponds to a scalar object\n",
    "5. Finally we assigned the attribute `'new_atribute'` with value `1.0`, to the existing **group**. \n",
    "\n",
    "And that's it! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2\n",
    "Create your own `HDF5` file including groups, datasets and attributes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modifying an existing `HDF5` file\n",
    "\n",
    "In lecture 5 we learned how to modify `csv` files using **pandas** library. Existing `HDF5` files can also be modified. Let us see how this work with an specific example. \n",
    "\n",
    "First let us create a new `HDF5` file example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "with h5py.File('test_file.hdf5', 'w') as t:\n",
    "    dat = np.random.random((10,10))\n",
    "    dset = t.create_dataset(\"rand2d\",data = dat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now open it using the `r+` keyword, which stands for read and write, as shown explicitly in our table above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset rand2d:  [[0.47303875 0.00185955 0.39730477 0.07430868 0.17485502 0.25681984\n",
      "  0.55515063 0.67084517 0.7680498  0.91349884]\n",
      " [0.35075328 0.78415693 0.57242067 0.13128179 0.95548179 0.62567705\n",
      "  0.72206224 0.45737436 0.60420352 0.0307579 ]\n",
      " [0.01371305 0.82773081 0.9960302  0.4083762  0.8294101  0.68678394\n",
      "  0.03190753 0.04539914 0.68200537 0.90963546]\n",
      " [0.39572538 0.88374697 0.5600418  0.78138835 0.72433941 0.09401458\n",
      "  0.51321568 0.87251261 0.6690137  0.50878722]\n",
      " [0.77729401 0.78459341 0.75890426 0.61670207 0.55321    0.19698551\n",
      "  0.74926632 0.57301041 0.70684834 0.97121521]\n",
      " [0.57296059 0.84465329 0.8492833  0.42233857 0.41338177 0.08172171\n",
      "  0.18735563 0.89391625 0.09626753 0.64020893]\n",
      " [0.90916676 0.94878361 0.232138   0.81820577 0.00689707 0.49200832\n",
      "  0.91192174 0.67840576 0.45701372 0.36064755]\n",
      " [0.30937057 0.99092873 0.42347961 0.281966   0.28216922 0.7679035\n",
      "  0.46525736 0.7260462  0.33013594 0.05166663]\n",
      " [0.98142504 0.59521607 0.41364011 0.91250429 0.94450926 0.02703629\n",
      "  0.07110943 0.87091236 0.21504772 0.72399554]\n",
      " [0.86886576 0.61912601 0.33631605 0.45439258 0.66634801 0.60730193\n",
      "  0.19930698 0.66718922 0.44659147 0.98573992]]\n",
      "\n",
      "keys after adding test_group and :  <KeysViewHDF5 ['rand2d', 'test_group']>\n",
      "\n",
      "geom_space data [  1.           1.09854114   1.20679264   1.32571137   1.45634848\n",
      "   1.59985872   1.75751062   1.93069773   2.12095089   2.32995181\n",
      "   2.55954792   2.8117687    3.0888436    3.39322177   3.72759372\n",
      "   4.09491506   4.49843267   4.94171336   5.42867544   5.96362332\n",
      "   6.55128557   7.19685673   7.90604321   8.68511374   9.54095476\n",
      "  10.48113134  11.51395399  12.64855217  13.89495494  15.26417967\n",
      "  16.76832937  18.42069969  20.23589648  22.22996483  24.42053095\n",
      "  26.82695795  29.47051703  32.37457543  35.56480306  39.06939937\n",
      "  42.9193426   47.14866363  51.79474679  56.89866029  62.50551925\n",
      "  68.6648845   75.43120063  82.86427729  91.0298178  100.        ]\n"
     ]
    }
   ],
   "source": [
    "test  = h5py.File('test_file.hdf5','r+')\n",
    "\n",
    "# To see we are able to use our file, let us for instance print the values contained in our dataset  \n",
    "print('Dataset rand2d: ', test['rand2d'][:])\n",
    "\n",
    "# Let us now for instance add a group into our existing file, a data set in that group, and an additional subgroup\n",
    "new_group = test.create_group('test_group')\n",
    "new_sub_group = new_group.create_group('test_sub_group')\n",
    "new_dset = new_group.create_dataset(\"geom_space\",data = np.geomspace(1,100,50))\n",
    "\n",
    "# Check that the group was added correctly by, for instance, checking the keys  \n",
    "print()\n",
    "print('keys after adding test_group and : ' , test.keys())\n",
    "\n",
    "# And access our `'geom_space'` dataset\n",
    "print()\n",
    "print('geom_space data', test['test_group/geom_space'][:])\n",
    "\n",
    "#Close the file\n",
    "test.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we check that our original `'test_file.hdf5'` file has saved all the changes made above by opening it using the `r` mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keys <KeysViewHDF5 ['rand2d', 'test_group']>\n",
      "\n",
      "geom_space_data [  1.           1.09854114   1.20679264   1.32571137   1.45634848\n",
      "   1.59985872   1.75751062   1.93069773   2.12095089   2.32995181\n",
      "   2.55954792   2.8117687    3.0888436    3.39322177   3.72759372\n",
      "   4.09491506   4.49843267   4.94171336   5.42867544   5.96362332\n",
      "   6.55128557   7.19685673   7.90604321   8.68511374   9.54095476\n",
      "  10.48113134  11.51395399  12.64855217  13.89495494  15.26417967\n",
      "  16.76832937  18.42069969  20.23589648  22.22996483  24.42053095\n",
      "  26.82695795  29.47051703  32.37457543  35.56480306  39.06939937\n",
      "  42.9193426   47.14866363  51.79474679  56.89866029  62.50551925\n",
      "  68.6648845   75.43120063  82.86427729  91.0298178  100.        ]\n"
     ]
    }
   ],
   "source": [
    "with h5py.File('test_file.hdf5','r') as t2:\n",
    "    print('keys', t2.keys())\n",
    "    print()\n",
    "    print('geom_space_data',  t2['test_group/geom_space'][:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once has to be careful when modifying `HDF5` files, since datasets added using already existing keywords as names, will overwrite the existing datasets. Similarly, `HDF5` files created with names of files already existing, will overwrite the existing files. \n",
    "\n",
    "Notice we have  interchangeably manipulate `HDF5` using or not the `with` blocks, to show the equivalence of the different ways of handle data files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
